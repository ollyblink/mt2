\chapter{Related Work and State of the Art}
Although the widest usage of the MapReduce programming model to date may be the one of Hadoop \cite{Hadoop} with its centralised master-slave architecture, recently, there have also been a number of attempts to transport it to a more decentralised setting in an endeavour to support currently popular Cloud platforms, pervasive grids, and/or mobile environments. Such endeavours address the problem of Hadoop (and similar MapReduce implementations) being designed for dedicate environments and not supporting dynamic environments with high churn rates \cite{CReSTIC-2677}.

\cite{Hadoop} is an open-source implementation of MapReduce (mainly implemented by Yahoo) enjoying a wide adoption and is often used for short jobs, where low response time is critical \cite{Zaharia:2008:IMP:1855741.1855744}. It's implementation closely resembles Google's \cite{Dean2008}, where master nodes manage a number of slave nodes. The input file resides in the distributed file system (HDFS \cite{Lin:2010:MMO:1851476.1851489}) and is split in even chunks replicated for fault-tolerance \cite{Zaharia:2008:IMP:1855741.1855744}. Output of map tasks are not replicated. \cite{Lin:2010:MMO:1851476.1851489}. task scheduler implicitly assumes cluster nodes to be homogeneous and tasks progress linearly to decide if a task should be re-executed (in homogeneous environments, execution should be more or less equal on each node). This makes Hadoop rather unrealistic for "office" settings, where commodity hardware may vary greatly in performance. 

\cite{Lin:2010:MMO:1851476.1851489} explore the limitations of Hadoop over volatile, non-dedicated resources. They propose the use of a hybrid architecture where a small set of reliable nodes are used to provide resources to volatile nodes called MOON. They demonstrated that Moon's data and task replication design greatly improved the quality of service of MapReduce when running on a hybrid resource architecture with many volatile and only a small set of dedicated nodes. However, there tests only included homogeneous configurations across nodes, creating natural heterogeneity only through node unavailability.

\cite{Marozzo2012a} recognised the problem of centralised master-slave architectures to not cope well with dynamic cloud infrastructures, where nodes may join or leave the network at high rates. Thus, they introduce a peer-to-peer model to manage node churn but also master failures and job recovery in a decentralised way. Each node may become a master or a slave at any given time dynamically, preserving a certain master/slave ratio. Slaves are assigned tasks to perform by the masters, which handle management, recovery, and coordination. To reduce job loss in case of master failures, each master may act as a backup master for a certain job, only executing it if the master primarily responsible for that job fails. Overall, the structure of different entities resembles very much the one of Hadoop, simply ported to a P2P setting. They were able to show that such an implementation provides better fault tolerance levels compared to a centralised implementations of MapReduce and only limited impact on network overhead. 

In a very similar direction goes the PER-MARE initiative that aimed at proposing scalable techniques to support existing MapReduce data-intensive applications in the context of loosely coupled networks (e.g. desktop grids) \cite{Steffenel2013}. The aim was two-fold to develop a MapReduce implementation for pervasive or desktop grids and to keep the implementation compatible to Hadoop's API while using a P2P environment. The hope was to be able to reuse existent applications over pervasive grids. The identified problem relied on the assumption that Hadoop and other MapReduce implementations are designed for dedicate environments and do not support environments with high node churn. The authors already hypothesised about using a DHT with controlled data replication as a solution to ensure fault tolerance without relying on full data replication. However, their first Prototype CONFIIT was abandoned \cite{Steffenel2013a} for the later CloudFIT implementation (see below) due to several problems that lead to an exponential increase in execution time with increasing data size, which made it unsuitable for the intended purpose.

CloudFIT \cite{Steffenel2015, Steffenel2015a}, which the authors advertise as a "Platform-as-a-Service (PaaS) middleware, allows the creation of private clouds over pervasive environments". The idea is to use private computers to set up a private "Cloud", and that MapReduce jobs are then distributed to this environment and executed in a P2P fashion. CloudFIT is, thus, built to support various P2P overlays and the authors show the performance of CloudFIT with both PAST and TomP2P against Hadoop. The results demonstrated CloudFIT to be able to achieve similar execution speeds as Hadoop while omitting the need of a dedicated cluster of computers. Data in CloudFIT is directly stored within the DHT of the corresponding overlay, such that it is replicated by a factor of k. Although such an implementation may not guarantee n-resiliency (meaning, replicating the data on each node), it is a reasonable assumption that fault tolerance may be ensured more than enough (provided at least a number of nodes stay alive and the complete dataset is replicated on these nodes) while drastically improving storage performance. Furthermore, not all the data is broadcasted but only the keys of each task, further reducing the network workload the authors showed in another study \cite{Steffenel2015a} to be one of the main problems in distributed environments for the performance of MapReduce tasks.

